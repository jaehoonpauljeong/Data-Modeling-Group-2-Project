{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10082591,"sourceType":"datasetVersion","datasetId":6216013},{"sourceId":10082633,"sourceType":"datasetVersion","datasetId":6216040},{"sourceId":10105710,"sourceType":"datasetVersion","datasetId":6233639}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Module installation","metadata":{}},{"cell_type":"code","source":"# !pip install langdetect\n# !pip install sentence_transformers\n# !pip install sacremoses\n# !pip install pymysql","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:59:35.170042Z","iopub.execute_input":"2024-12-03T00:59:35.170689Z","iopub.status.idle":"2024-12-03T00:59:43.533617Z","shell.execute_reply.started":"2024-12-03T00:59:35.170652Z","shell.execute_reply":"2024-12-03T00:59:43.532267Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Extractor","metadata":{}},{"cell_type":"code","source":"# import re\n# from collections import defaultdict\n\n# class DataExtractor:\n#     def __init__(self):\n#         self.patterns = {\n#             \"name\": r\"<name>(.*?)</name>\",\n#             \"source\": r\"<source>(.*?)</source>\",\n#             \"url-name\": r\"<url-name>(.*?)</url-name>\",\n#             \"action\": r\"<action>(.*?)</action>\",\n#         }\n\n#     def extract(self, policy_xml):\n#         extracted_data = defaultdict(str)\n#         for key, pattern in self.patterns.items():\n#             match = re.search(pattern, policy_xml)\n#             if match:\n#                 extracted_data[key] = match.group(1)\n#         return extracted_data\n\n\n# # Example usage:\n# policy_xml = \"\"\"\n# <i2nsf-cfi-policy>\n#   <name>politica_de_seguridad_para_bloquear_rrss</name>\n#   <rules>\n#     <name>bloquear_acceso_rrss_durante_horario_laboral</name>\n#     <condition>\n#       <firewall>\n#         <source>employees</source>\n#       </firewall>\n#       <url-category>\n#         <url-name>sns-websites</url-name>\n#       </url-category>\n#     </condition>\n#     <action>\n#       <primary-action>\n#         <action>drop</action>\n#       </primary-action>\n#     </action>\n#   </rules>\n# </i2nsf-cfi-policy>\n# \"\"\"\n\n# extractor = DataExtractor()\n# extracted = extractor.extract(policy_xml)\n# print(extracted)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:46:40.311466Z","iopub.execute_input":"2024-12-03T00:46:40.311725Z","iopub.status.idle":"2024-12-03T00:46:40.349995Z","shell.execute_reply.started":"2024-12-03T00:46:40.311698Z","shell.execute_reply":"2024-12-03T00:46:40.349182Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Multilingual Support Layer","metadata":{}},{"cell_type":"code","source":"# from langdetect import detect\n# from transformers import pipeline, AutoTokenizer, AutoModel\n# from sentence_transformers import SentenceTransformer, util\n\n# class MultilingualSupport:\n#     def __init__(self):\n#         self.language_detector = detect\n#         self.translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-mul-en\")\n#         self.embedder = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n\n#     def detect_language(self, text):\n#         return self.language_detector(text)\n\n#     def translate_to_english(self, text):\n#         return self.translator(text)[0][\"translation_text\"]\n\n#     def compute_similarity(self, text1, text2):\n#         embedding1 = self.embedder.encode(text1, convert_to_tensor=True)\n#         embedding2 = self.embedder.encode(text2, convert_to_tensor=True)\n#         return util.pytorch_cos_sim(embedding1, embedding2).item()\n\n\n# # Example usage:\n# msl = MultilingualSupport()\n# text = \"bloquear el acceso a redes sociales durante el horario laboral\"\n# detected_lang = msl.detect_language(text)\n# translated = msl.translate_to_english(text)\n# similarity = msl.compute_similarity(translated, \"block access to social networks during office hours\")\n\n# print(f\"Detected Language: {detected_lang}\")\n# print(f\"Translation: {translated}\")\n# print(f\"Similarity Score: {similarity}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:50:20.878348Z","iopub.execute_input":"2024-12-03T00:50:20.878700Z","iopub.status.idle":"2024-12-03T00:50:35.092723Z","shell.execute_reply.started":"2024-12-03T00:50:20.878669Z","shell.execute_reply":"2024-12-03T00:50:35.091938Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Converter","metadata":{}},{"cell_type":"code","source":"# from collections import OrderedDict\n\n# class Converter:\n#     def convert(self, high_data, db):\n#         low_data = OrderedDict()\n#         for key, value in high_data.items():\n#             low_attr = db.mapAttr(key)\n#             if db.getUserData(value):\n#                 user_data = db.getUserData(value)\n#                 low_data[low_attr] = user_data[\"mac\"] or user_data[\"ip_range\"]\n#             else:\n#                 low_data[low_attr] = value\n#         return low_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:51:31.986791Z","iopub.execute_input":"2024-12-03T00:51:31.987401Z","iopub.status.idle":"2024-12-03T00:51:31.992652Z","shell.execute_reply.started":"2024-12-03T00:51:31.987369Z","shell.execute_reply":"2024-12-03T00:51:31.991677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Policy Generator","metadata":{}},{"cell_type":"code","source":"# import json\n\n# class PolicyGenerator:\n#     def generate(self, low_level_data, format_type=\"json\"):\n#         if format_type == \"json\":\n#             return json.dumps(low_level_data, indent=4)\n#         elif format_type == \"xml\":\n#             # Basic XML formatting\n#             xml_str = \"<policy>\"\n#             for key, value in low_level_data.items():\n#                 xml_str += f\"<{key}>{value}</{key}>\"\n#             xml_str += \"</policy>\"\n#             return xml_str\n\n\n# # Example usage:\n# low_level_data = {\"source\": \"employees\", \"action\": \"drop\"}\n# generator = PolicyGenerator()\n# policy_json = generator.generate(low_level_data, \"json\")\n# policy_xml = generator.generate(low_level_data, \"xml\")\n\n# print(\"JSON Policy:\", policy_json)\n# print(\"XML Policy:\", policy_xml)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:51:35.055241Z","iopub.execute_input":"2024-12-03T00:51:35.056004Z","iopub.status.idle":"2024-12-03T00:51:35.062067Z","shell.execute_reply.started":"2024-12-03T00:51:35.055974Z","shell.execute_reply":"2024-12-03T00:51:35.061184Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Integration","metadata":{}},{"cell_type":"code","source":"# import sys\n# sys.path.append('/kaggle/input/i2nsfdb/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T00:57:34.672537Z","iopub.execute_input":"2024-12-03T00:57:34.673241Z","iopub.status.idle":"2024-12-03T00:57:34.676936Z","shell.execute_reply.started":"2024-12-03T00:57:34.673196Z","shell.execute_reply":"2024-12-03T00:57:34.676126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pymysql\n# import i2nsfDB\n\n\n# # Example Workflow\n# extracted_data = extractor.extract(policy_xml)\n# translated_data = {k: msl.translate_to_english(v) for k, v in extracted_data.items()}\n# low_level_data = Converter().convert(translated_data, i2nsfDB)\n# policy_output = PolicyGenerator().generate(low_level_data, \"json\")\n\n# print(policy_output)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T01:00:25.323085Z","iopub.execute_input":"2024-12-03T01:00:25.323763Z","iopub.status.idle":"2024-12-03T01:00:25.384013Z","shell.execute_reply.started":"2024-12-03T01:00:25.323728Z","shell.execute_reply":"2024-12-03T01:00:25.382733Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# START OF THE POSSIBLE PROJECT ","metadata":{}},{"cell_type":"code","source":"!pip install openai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T05:54:14.612187Z","iopub.execute_input":"2024-12-05T05:54:14.612809Z","iopub.status.idle":"2024-12-05T05:54:26.672561Z","shell.execute_reply.started":"2024-12-05T05:54:14.612767Z","shell.execute_reply":"2024-12-05T05:54:26.671308Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-1.56.2-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nCollecting jiter<1,>=0.4.0 (from openai)\n  Downloading jiter-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.10.2)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\nDownloading openai-1.56.2-py3-none-any.whl (389 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading jiter-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: jiter, openai\nSuccessfully installed jiter-0.8.0 openai-1.56.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nOPENAI_API_KEY = user_secrets.get_secret(\"Open_AI\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T05:54:36.287245Z","iopub.execute_input":"2024-12-05T05:54:36.287648Z","iopub.status.idle":"2024-12-05T05:54:36.588146Z","shell.execute_reply.started":"2024-12-05T05:54:36.287607Z","shell.execute_reply":"2024-12-05T05:54:36.587119Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import openai\n\nopenai.api_key = OPENAI_API_KEY\nmodel = \"gpt-4o-mini\"\n\ndef generate_policy(policy_text, model=\"gpt-4o-mini\"):\n    \"\"\"\n    Converts natural language policy into an XML security policy.\n    Includes an example and IETF draft content for context.\n    \"\"\"\n    # Example to guide the model\n    example_input = \"Block my son's computers from malicious websites.\"\n    example_output = \"\"\"\n<i2nsf-cfi-policy\n    xmlns=\"urn:ietf:params:xml:ns:yang:ietf-i2nsf-cfi-policy\">\n    <name>block_web_security_policy</name>\n    <rules>\n        <name>block_web</name>\n        <condition>\n            <firewall-condition>\n                <source>Son's_PC</source>\n            </firewall-condition>\n            <url-condition>\n                <url-name>malicious_websites</url-name>\n            </url-condition>\n        </condition>\n        <actions>\n            <primary-action>\n                <action>drop</action>\n            </primary-action>\n        </actions>\n    </rules>\n</i2nsf-cfi-policy>\n    \"\"\"\n\n    # Load additional context from I2NSF's official IETF draft\n    ietf_context = \"\"\"\n    The I2NSF schema follows an Event-Condition-Action (ECA) model. XML policies should have the following structure:\n    - <i2nsf-cfi-policy>: Root tag.\n    - <name>: Unique name for the policy.\n    - <rules>: Defines specific rules.\n        - <condition>: Defines matching criteria.\n        - <actions>: Defines actions to be taken.\n    \"\"\"\n\n    # Combine all elements into the prompt\n    prompt = f\"\"\"\n    You are an expert in XML schema and I2NSF security policies. Convert the following natural language input into an XML security policy compliant with the I2NSF schema. Use the Event-Condition-Action (ECA) format and ensure the XML is valid.\n\n    Here is an example for reference:\n    Input: {example_input}\n    Output: {example_output}\n\n    Additional Context:\n    {ietf_context}\n\n    Now, generate the XML for the following input:\n    Input: {policy_text}\n\n    Output:\n    \"\"\"\n    \n    response = openai.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are an XML schema and I2NSF policy expert.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\n    \n    return response.choices[0].message.content\n\n# Example usage\npolicy_text = \"block SNS access during office hours.\"\nxml_policy = generate_xml_policy_with_context(policy_text, model)\n\nprint(\"Generated XML Policy:\")\nprint(xml_policy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T05:57:45.782933Z","iopub.execute_input":"2024-12-05T05:57:45.783887Z","iopub.status.idle":"2024-12-05T05:57:48.692914Z","shell.execute_reply.started":"2024-12-05T05:57:45.783826Z","shell.execute_reply":"2024-12-05T05:57:48.691924Z"}},"outputs":[{"name":"stdout","text":"Generated XML Policy:\n```xml\n<i2nsf-cfi-policy\n    xmlns=\"urn:ietf:params:xml:ns:yang:ietf-i2nsf-cfi-policy\">\n    <name>block_sns_access_policy</name>\n    <rules>\n        <name>block_sns_office_hours</name>\n        <condition>\n            <firewall-condition>\n                <time>\n                    <start-time>09:00</start-time>\n                    <end-time>17:00</end-time>\n                </time>\n            </firewall-condition>\n            <url-condition>\n                <url-name>social_networking_sites</url-name>\n            </url-condition>\n        </condition>\n        <actions>\n            <primary-action>\n                <action>drop</action>\n            </primary-action>\n        </actions>\n    </rules>\n</i2nsf-cfi-policy>\n```\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# END OF THE POSSIBLE PROJECT ","metadata":{}}]}
